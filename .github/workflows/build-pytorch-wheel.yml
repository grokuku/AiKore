# .github/workflows/build-pytorch-wheel.yml
name: "Build PyTorch Wheel"

on:
  workflow_dispatch:
    inputs:
      pytorch_version:
        description: 'PyTorch git tag (e.g., v2.9.0)'
        required: true
        default: 'v2.9.0'
      cuda_version_tag:
        description: 'NVIDIA CUDA base image tag (e.g., 12.4.1-cudnn-devel-ubuntu22.04)'
        required: true
        default: '12.4.1-cudnn-devel-ubuntu22.04'
      torch_cuda_arch_list:
        description: 'Space-separated list of CUDA architectures (e.g., "8.9")'
        required: true
        default: '8.9'

jobs:
  build-pytorch:
    name: Compile PyTorch wheel
    runs-on: ubuntu-latest
    permissions:
      contents: read
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build PyTorch wheel
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./pytorch.Dockerfile
          # Do not push the image, we only want the build result
          push: false
          # Target the final 'scratch' stage which only contains the wheel
          target: final
          # Export the build result to a local directory
          outputs: type=local,dest=./wheel_output
          # Pass the workflow inputs as build arguments to the Dockerfile
          build-args: |
            PYTORCH_TAG=${{ github.event.inputs.pytorch_version }}
            BASE_IMAGE_TAG=${{ github.event.inputs.cuda_version_tag }}
            TORCH_CUDA_ARCH_LIST=${{ github.event.inputs.torch_cuda_arch_list }}

      - name: List output files
        run: ls -R ./wheel_output

      - name: Upload wheel as artifact
        uses: actions/upload-artifact@v4
        with:
          name: pytorch-wheel
          path: ./wheel_output/dist/*.whl
          retention-days: 7
